Deploy openshift cluster 3.9 (multinode)
------------------------------
Note** Scan thru complete file, have a look at instructions /notes and then start the setup..

--setup 4 centos 7 machines within vmbox
--make sure they can ping each other, ssh each other for root user without password
--setup DNS or update /etc/hosts as shown

#in /etc/hosts of all 4 machines..

ip1 master console.ww.openshift.test.dev.io
ip2 infra
ip3 node1
ip4 node2

#to be done on all 4 nodes
------------
#To check kernel
rpm -q kernel --last | head -n 1 | awk '{print $1}' 

#Install the relevant packages
#do not install/use docker-1.13.1 if this machine was already installed with docker as done in 'single-node-setup'
#if this is first time setup, then we can goahead with docker-1.13.1 

yum install -y wget git zile nano net-tools docker-1.13.1 bind-utils iptables-services bridge-utils bash-completion
kexec-tools openssl-devel httpd-tools NetworkManager python-cryptography python2-pip python-devel python-passlib 
java-1.8.0-openjdk-headless "@Development Tools" sos psacct

#Install repositories:
rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
sed -i -e "s/^enabled=1/enabled=0/" /etc/yum.repos.d/epel.repo

#start and enable networkmanager and docker services
systemctl start NetworkManager
systemctl enable NetworkManager
systemctl status NetworkManager

systemctl start docker
systemctl enable docker
systemctl status docker
--------------------

#Install Ansible Package and Clone OpenShift-Ansible Git Repo on Master Machine only uing EPEL Repo:
yum -y --enablerepo=epel install ansible pyOpenSSL (just on master)
curl -o ansible.rpm https://releases.ansible.com/ansible/rpm/release/epel-7-x86_64/ansible-2.6.5-1.el7.ans.noarch.rpm
yum -y --enablerepo=epel install ansible.rpm


#make sure all nodes have ssh password less access

git clone https://github.com/openshift/openshift-ansible.git
cd openshift-ansible/
git fetch
git checkout release-3.11

sudo mkdir -p /etc/origin/master
#create an empty file
vi /etc/origin/master/htpasswd

#create an inventory file and add the content
vi inventory.ini
------------
[OSEv3:children]
masters
nodes
etcd

[masters]
192.168.251.64 openshift_ip=192.168.251.64 openshift_schedulable=true ansible_connection=local ansible_become=yes

[etcd]
192.168.251.64 openshift_ip=192.168.251.64 ansible_connection=local ansible_become=yes

[nodes]
192.168.251.64 openshift_ip=192.168.251.64 openshift_schedulable=true openshift_node_group_name="node-config-master" 
192.168.251.65 openshift_ip=192.168.251.65 openshift_node_group_name="node-config-infra" openshift_schedulable=true ansible_become=yes ansible_sudo_pass=abcd1234 ansible_user=root ansible_ssh_pass=abcd1234
192.168.251.66 openshift_ip=192.168.251.66 openshift_schedulable=true openshift_node_group_name="node-config-compute" ansible_become=yes ansible_sudo_pass=abcd1234 ansible_user=root ansible_ssh_pass=abcd1234
192.168.251.67 openshift_ip=192.168.251.67 openshift_schedulable=true openshift_node_group_name="node-config-compute" ansible_become=yes ansible_sudo_pass=abcd1234 ansible_user=root ansible_ssh_pass=abcd1234

[OSEv3:vars]
openshift_additional_repos=[{'id':'centos-paas','name':'centos-paas','baseurl':'https://buildlogs.centos.org/centos/7/paas/x86_64/openshift-origin311','gpgcheck':'0','enabled':'1'}]
ansible_become=yes
ansible_sudo=true
ansible_ssh_user=root
enable_excluders=False
enable_docker_excluder=False
ansible_service_broker_install=False
containerized=True
os_sdn_network_plugin_name='redhat/openshift-ovs-multitenant'
openshift_disable_check=disk_availability,docker_storage,memory_availability,docker_image_availability

#openshift_node_kubelet_args={'pods-per-core': ['10']}

#we can mention here enterprise if we have required license
deployment_type=origin
openshift_deployment_type=origin

openshift_metrics_image_version="v3.11"
openshift_logging_image_version="v3.11"
openshift_logging_elasticsearch_proxy_image_version="v1.0.0"
openshift_logging_es_nodeselector={"node-role.kubernetes.io/infra":"true"}
logging_elasticsearch_rollout_override=false
osm_use_cockpit=true

openshift_metrics_install_metrics=True
openshift_logging_install_logging=True

#put the router on dedicated infra node
openshift_hosted_router_selector='region=infra'
openshift_master_default_subdomain=apps.ww.openshift.test.dev
openshift_master_cluster_public_hostname=console.ww.openshift.test.dev
openshift_master_cluster_hostname=osh1.europe-west3-c.c.model-block-277513.internal
openshift_master_api_port=8443
openshift_master_console_port=8443

#put the image registry on dedicated infra node
template_service_broker_selector={"region":"infra"}

#use htpasswd authentication with demo/demo
openshift_master_identity_providers=[{'name': 'htpasswd_auth','login':'true','challenge':'true','kind':'HTPasswdPasswordIdentityProvider'}]
openshift_master_htpasswd_file='/etc/origin/master/htpasswd'
------
#run prerequisites to check if all configurations are fine..

ansible-playbook -i inventory.ini playbooks/prerequisites.yml

#if ansible version gives a problem(we can go for a previous version)
yum remove ansible
pip install ansible==2.6.6
ansible --version

================
Pull below docker images on master node if you want the installation to be quicker
#if doing this step, change origin version accordingly

docker pull registry.fedoraproject.org/latest/etcd:latest && docker pull docker.io/openshift/openvswitch:v3.9.0 && docker pull docker.io/openshift/node:v3.9.0 && docker pull docker.io/openshift/origin:v3.9.0

Pull below docker images on infra,node1,node2 if you want the installation to be quicker
docker pull docker.io/openshift/openvswitch:v3.9.0 && docker pull docker.io/openshift/node:v3.9.0 && docker pull docker.io/openshift/origin:v3.9.0

#note** if registry.fedoraproject.org/latest/etcd:latest doesn't work use
bitnami/etcd:latest
================
on master:
docker images

on other nodes:
docker images
================
#once prereq completed without error, use the below ansible playbook to deploy 
OpenShift cluster on master:

ansible-playbook -i inventory.ini playbooks/deploy_cluster.yml

#only if error about /etcd pull which we changed to bitnami
edit vi /root/openshift-ansible/roles/etcd/tasks/main.yml and replace {{etcd_image}}
command: docker pull "bitnami/etcd:latest"

Have to wait 30-40 min before installation completes

---
while deployment is happening, check
oc whoami
oc get nodes
oc get nodes -o wide
---

#once installation is completed, create a admin user in OpenShift with Password 'Pas$$w0rd'

ls -l /etc/origin/master/htpasswd
cat /etc/origin/master/htpasswd
htpasswd -b /etc/origin/master/htpasswd ${USERNAME} ${PASSWORD}
or
htpasswd /etc/origin/master/htpasswd admin
New password:
retype oassword:

cat /etc/origin/master/htpasswd

#assign cluster-admin role to admin user:
oc adm policy add-cluster-role-to-user cluster-admin admin
oc adm policy add-cluster-role-to-user cluster-admin ${USERNAME}

#login as admin
oc login
admin
Paa$$w0rd
===================











